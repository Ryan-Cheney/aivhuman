# -*- coding: utf-8 -*-
"""FaceForensics_XceptionNet_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JCakmxJcWPO1qetanxiOOdhYuCfmZmZb
"""

import torch
import timm
import pandas as pd
import numpy as np
from torch.utils.data import Dataset, DataLoader, Subset
from torchvision import transforms
from PIL import Image as PILImage
import os

"""## Dataset extracted from Face Forensics Videos. DataLoader Creation"""

class CustomDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.data['file_name'].iloc[idx])
        try:
            image = PILImage.open(img_path).convert('RGB')
        except (FileNotFoundError, Exception):
            image = PILImage.new('RGB', (128, 128), color=(0, 0, 0))  # Handle errors by returning a black image
        if self.transform:
            image = self.transform(image)
        return image

# Define the transformations
train_transforms = transforms.Compose([
    transforms.Resize([128, 128]),
    transforms.ToTensor(),
])

"""## XceptionNet Model"""

model = timm.create_model('xception', pretrained=True, num_classes=1)
model = model.to(device)
print(model)

"""## Training code"""

train_dataset = CustomDataset(csv_file='train.csv', root_dir='/content', transform=train_transforms)
num_samples = 100
total_samples = len(train_dataset)
train_indices = np.random.choice(total_samples, num_samples, replace=False)
train_subset = Subset(train_dataset, train_indices)
train_data_loader = DataLoader(train_subset, batch_size=32, shuffle=False)  # No need to shuffle for feature extraction

# Load the pre-trained model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = timm.create_model('xception', pretrained=True, num_classes=1)
model = model.to(device)
model.eval()  # Set the model to evaluation mode

# Extract features
all_features = []
with torch.no_grad():
    for inputs in train_data_loader:
        inputs = inputs.to(device)
        features = model.forward_features(inputs.float())
        features = torch.nn.functional.adaptive_avg_pool2d(features, 1)
        features = features.view(features.size(0), -1)
        all_features.append(features.cpu().numpy())

# Save the extracted features
all_features = np.concatenate(all_features, axis=0)
df = pd.DataFrame(all_features)
df.to_csv('extracted_features1.csv', index=False)