# -*- coding: utf-8 -*-
"""DINO-ViT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13ugiC7WYknUXrZS7XmBTlcbVhhPCRzSd
"""

from google.colab import files
files.upload()  # This will prompt you to upload kaggle.json

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d alessandrasala79/ai-vs-human-generated-dataset

!unzip -qq ai-vs-human-generated-dataset.zip

# load model
from transformers import AutoImageProcessor, AutoModel

processor = AutoImageProcessor.from_pretrained("facebook/dino-vits8")
model = AutoModel.from_pretrained("facebook/dino-vits8")

!pip install torch torchvision timm

import torch
import timm
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import os

# Load DINO-ViT model (base version)
model = timm.create_model("vit_base_patch16_224.dino", pretrained=True)
model.eval()  # Set to evaluation mode

transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize image
    transforms.ToTensor(),          # Convert to tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize
])

image_base_dir = "/content/train_data"

train_df = pd.read_csv("/content/train.csv")

for index, row in train_df.iterrows():
    img_path = os.path.join('/content', row['file_name'])

    if os.path.exists(img_path):
        # print(f"Image found: {img_path}")
        pass
    else:
        print(f"Missing image: {img_path}")

import numpy as np

def extract_features(img_path, model):
    img = Image.open(img_path).convert("RGB")
    img_tensor = transform(img).unsqueeze(0)

    with torch.no_grad():
        features = model(img_tensor)  # Extract features

    return features.flatten().cpu().numpy()

image_base_dir = "/content/train_data"
train_csv_path = "/content/train.csv"

df = pd.read_csv(train_csv_path)

# random sample
df_sampled = df.sample(n=5000, random_state=42)

all_features = []

# go through the train dataset and extract features
for index, row in df_sampled.iterrows():
    img_path = os.path.join('/content', row['file_name'])

    if os.path.exists(img_path):
        features = extract_features(img_path, model)
        all_features.append(features)
    else:
        print(f"Missing image: {img_path}")

    if (index + 1) % 100 == 0:  # Update progress every 100 images
            print(f"Processed {index + 1}/{len(df_sampled)} images")

all_features_array = np.array(all_features)

print("Feature extraction completed.")

all_features_array

all_features

print(len(all_features[0]))

all_features_array.shape

import pandas as pd

# Convert features to a DataFrame and save as CSV
features_df = pd.DataFrame(all_features_array)
features_df.to_csv("/content/all_features.csv", index=False)
print("Features saved to 'all_features.csv'")